{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAcwxYQ-W6w5"
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "Standard CNNs are comprised of three types of layers: convolutional layers, pooling layers (for subsampling) and fully-connected layers.  When  these  layers  are  stacked, a CNN architecture has been formed. A simplified CNN architecture for MNIST image classification is illustrated in Figure 2.\n",
    "\n",
    "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Typical_cnn.png\"><img width=\"718\" alt=\"Typical cnn\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/512px-Typical_cnn.png\"></a>\n",
    "\n",
    "**Figure 1:** A common form of CNN architecture in which convolutional layers are stacked continuously before being passed through the pooling (subsampling) layer for subsampling, output of which are the features that will be fed to the fully connected (or dense) layers for final output. Source: Wikimedia\n",
    "\n",
    "\n",
    "It is important to note that simply understanding the overall architecture of a CNN architecture will not suffice. The creation and optimisation of these models can take quite some time, and can be quite confusing. We will now explore in detail the individual layers, detailing their hyperparameters and connectivities.\n",
    "\n",
    "## Convolutional operation\n",
    "\n",
    "### filters (i.e. kernels) and feature maps (i.e. activations)\n",
    "As we glide through the input, the scalar product is calculated for each value in that filter, or kernel (Figure 2). From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These are commonly known as **activations**.\n",
    "\n",
    "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://d2l.ai/_images/correlation.svg\"><img width=\"500\" alt=\"Typical cnn\" src=\"https://d2l.ai/_images/correlation.svg\"></a>\n",
    "\n",
    "**Figure 2:** Illustration of a signle step in convolutional operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation:  0×0+1×1+3×2+4×3=19. \n",
    "\n",
    "Every kernel will have a corresponding activation/feature map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n",
    "\n",
    "These kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map.\n",
    "\n",
    "One of the key differences compared to the MLP is that the neurons that the layers within the CNN are comprised of neurons organised into three dimensions, the spatial dimensionality of the input **(height, width, and the depth)**. The depth is the third dimension of an activation volume, that is the number of filters/kernels/feature-maps used. Unlike standard MLPs, the neurons within any given layer will only connect to a small region (receiptive field) of the layer preceding it.\n",
    "\n",
    "### stride and padding\n",
    "We are also able to define the **stride** in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example, if we were to set a stride as 1 then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n",
    "\n",
    "**Zero-padding** is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of theoutput volumes. It is important to understand through the use of these tehcniques, we will in turn alter the spatial dimensionality of the convolutional layers' output. We can calculate this using the following method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVBynOv7XUId"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUS: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(f\"No GPUS: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QXfkQ6w0W6w6"
   },
   "outputs": [],
   "source": [
    "def calculate_conv_output(height, width, depth, kernel_size, zero_padding, stride):\n",
    "    # Receptive field size = kernel size.\n",
    "    \n",
    "    volume_size = (height*width)*depth\n",
    "    z = (zero_padding*zero_padding)\n",
    "    \n",
    "    return ((volume_size - kernel_size) + z) / stride + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VgiV_Q-W6w7"
   },
   "source": [
    "If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input. \n",
    "\n",
    "\n",
    "See the slides for lecture10-CNNs for more information on CNN. \n",
    "Or, the standford course on CNNs https://cs231n.github.io/convolutional-networks/\n",
    "Or go through the short tutorial for the basic components in a ConvNet\n",
    "https://machinelearningmastery.com/crash-course-convolutional-neural-networks/\n",
    "\n",
    "\n",
    "## Task One: MNIST Classification\n",
    "\n",
    "Using the slides given last week, build a CNN to classify MNIST digits:\n",
    "\n",
    "Last week we reduced the data dimensionality with PCA prior to appl a feedforward neural network. This time, we'll train a network on the complete image and use a CNN, a sparsely connected network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xgh5UHREfMDt"
   },
   "source": [
    "\n",
    "#### Just recall, in last practical, we learn how to build a simple fully connected neural network, aka Multilayer Perceptron (MLP) using dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvyGFH_4W6w4",
    "outputId": "9fe23acd-1442-406e-d48c-dd458e1115e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "# Good Practice Klaxon: Free your memory from previously made models.\n",
    "clear_session()\n",
    "\n",
    "# Create a new blank model\n",
    "model = Sequential()\n",
    "# Set input of size (4,) denotes that we can accept variable amounts of data)\n",
    "model.add(Input((4,)))\n",
    "model.add(Dense(2, activation=\"relu\"))\n",
    "# And finally, add an output layer of shape 1\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Print out a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uQFv4AOhu-v"
   },
   "source": [
    "Next, prepare the data. Notice the difference in the shape of the input data (due to the choice of different model architectures, this time a CNN in contrast to MLP used in last practical). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLjix5EeW6w7",
    "outputId": "baec2bad-8d25-4763-e2ce-0d6082f7de61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "X_dev shape:(60000, 28, 28, 1)\n",
      "60000 development samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "width = 28\n",
    "height = 28\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_dev, y_dev), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape for CNN\n",
    "X_dev = X_dev.reshape(X_dev.shape[0], height, width, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], height, width, 1)\n",
    "input_shape = (width, height, 1)\n",
    "\n",
    "\n",
    "# Make it faster. \n",
    "X_dev = X_dev.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_dev /= 255\n",
    "X_test /= 255\n",
    "print(f'X_dev shape:{X_dev.shape}')\n",
    "print(X_dev.shape[0], 'development samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_dev = to_categorical(y_dev, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhr92BFeSLVQ"
   },
   "source": [
    "Next, to follow the usual procedure for ML model development we need to set aside a validation set from the original training set for model selection, i.e. to tune the hyperparametters and model architectures. \n",
    "\n",
    "Here we chose hold-out cross-validation, splitting the data using the ScikitLearn function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split).\n",
    "\n",
    "Make sure to set **the random state** for reproducibility.\n",
    "E.g. \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.33, **random_state**=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "26NvMYG7TB2m"
   },
   "outputs": [],
   "source": [
    "# Split the development set into training and validationn set (1/6 of total dev set)\n",
    "# Your code here: \n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyIf7LMuW6w8"
   },
   "source": [
    "Build your convolutional neural networks below (you can get some insiration from this [keras example](https://keras.io/examples/vision/mnist_convnet/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKcnyv0SW6w9",
    "outputId": "bec54ffa-e4bb-4615-bdf9-7f37fb053ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 596,042\n",
      "Trainable params: 596,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "\n",
    "# Use function to define different models for reuse in experimments\n",
    "def create_cnn_model():\n",
    "    model = Sequential()    \n",
    "    model.add(Input(shape=(28,28,1,)))\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
    "    model.add(Flatten())     # Flatten, and add a fully connected layer\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax')) # Last layer: 10 class nodes, with dropout    \n",
    "    return model\n",
    "\n",
    "model=create_cnn_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egloE1oaW6w9"
   },
   "source": [
    "Note that we have about half a million parameters. With a strong optimizer like Adam, and a big dataset like MNIST, this shouldn't be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfsZ5rUSu_Eg"
   },
   "source": [
    "Also consider using GPU for accelerated computing if training is too slow using CPU only. \n",
    "\n",
    "In colab, you can easily add GPU to your runtime: just go to the top menu, click \"Runtime\"->\"Change runtime type\" -> \"Accelerater hardware\" is by default None, you can select \"GPU\" or \"TPU\" here.\n",
    "\n",
    "You can also upload the notebook to Kaggle and run it there with GPU accelorated training. \n",
    "\n",
    "TensorFlow and Keras will automatically execute on GPU if a GPU is available, so there’s nothing more you need to do after you’ve selected the GPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FwtAQaPW6w-",
    "outputId": "26a7f205-73fb-46f8-e9d0-5acc75243183"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model, iterating on the data in batches of 32 samples\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1133\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1127\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m cluster_coordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   1128\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[0;32m   1131\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1132\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1149\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1364\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1363\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1152\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m-> 1152\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m \u001b[43mselect_data_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_data_adapter_compatibility(adapter_cls)\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m adapter_cls(\n\u001b[0;32m   1155\u001b[0m     x,\n\u001b[0;32m   1156\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     distribution_strategy\u001b[38;5;241m=\u001b[39mds_context\u001b[38;5;241m.\u001b[39mget_strategy(),\n\u001b[0;32m   1166\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:988\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:988\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcan_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:227\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.can_handle\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m   flat_inputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(y)\n\u001b[1;32m--> 227\u001b[0m tensor_types \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tensor_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_tensor\u001b[39m(v):\n\u001b[0;32m    230\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, tensor_types):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1635\u001b[0m, in \u001b[0;36m_get_tensor_types\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_tensor_types\u001b[39m():\n\u001b[0;32m   1634\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1635\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ops\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, pd\u001b[38;5;241m.\u001b[39mSeries, pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[0;32m   1638\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     is_numpy_dev,\n\u001b[0;32m     20\u001b[0m     np_version_under1p21,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[0;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[0;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Appender,\n\u001b[0;32m      4\u001b[0m     Substitution,\n\u001b[0;32m      5\u001b[0m     cache_readonly,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     hash_array,\n\u001b[0;32m     10\u001b[0m     hash_pandas_object,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     Any,\n\u001b[0;32m      8\u001b[0m     Callable,\n\u001b[0;32m      9\u001b[0m     Mapping,\n\u001b[0;32m     10\u001b[0m     cast,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     F,\n\u001b[0;32m     17\u001b[0m     T,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     NaT,\n\u001b[0;32m     16\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     iNaT,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsoy3QHENhPI"
   },
   "source": [
    "**Question:**\n",
    "if GPU accelerating mode is enabled, how to change the batch size (assuming  current batch size is 32) to allow better use of the GPU?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI00mDc-N6qG"
   },
   "source": [
    "Generat learning curves by e.g.plotting the training and validation loss (or accuracy) side by side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "nbfpVahSOGNb",
    "outputId": "ad02808b-bb6d-4e38-e74c-353551c2a619"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3YUlEQVR4nO3dd3hUZfbA8e9JJ4WWQJAEBJQElRYIoGKh2FBARVRYdxVdG+taFxWwgCCurq7rj7WX1dVVsa0IlsWVIqyVUES6gChBaaEkIaTO+f0xN8MkTCAJmdyU83mePLnlvfeeuZA585b7jqgqxhhjTHkhbgdgjDGmbrIEYYwxJiBLEMYYYwKyBGGMMSYgSxDGGGMCsgRhjDEmIEsQplaIyCciclVNl3WTiGwWkbOCcF4VkeOd5WdF5L7KlK3Gda4QkU+rG+dhzjtARDJr+rym9oW5HYCpu0Qk1281GigASpz1G1T19cqeS1WHBKNsQ6eqN9bEeUSkA/AjEK6qxc65Xwcq/W9oGh9LEKZCqhpbuiwim4FrVfWz8uVEJKz0TccY03BYE5OpstImBBG5W0S2AS+LSAsR+VBEdorIHmc52e+YBSJyrbM8RkT+JyKPOWV/FJEh1SzbUUQWikiOiHwmIk+JyL8qiLsyMU4VkS+c830qIgl++38nIj+JSJaI3HOY+9NPRLaJSKjftotFZIWz3FdEvhKRvSLyq4g8KSIRFZzrFRF50G/9TueYX0TkmnJlLxCRZSKSLSJbRGSy3+6Fzu+9IpIrIqeU3lu/408VkcUiss/5fWpl783hiMgJzvF7RWSViAz323e+iKx2zrlVRMY52xOcf5+9IrJbRBaJiL1f1TK74aa62gAtgWOB6/H+X3rZWW8PHACePMzx/YB1QALwF+AlEZFqlH0D+BaIByYDvzvMNSsT42+Aq4HWQARQ+oZ1IvCMc/62zvWSCUBVvwH2A4PKnfcNZ7kEuN15PacAg4E/HCZunBjOc+I5G+gMlO//2A9cCTQHLgDGishFzr4znN/NVTVWVb8qd+6WwEfAdOe1PQ58JCLx5V7DIffmCDGHA7OBT53jbgZeF5FUp8hLeJsr44CuwDxn+5+ATKAVkAhMBGxeoFpmCcJUlweYpKoFqnpAVbNU9T1VzVPVHGAacOZhjv9JVV9Q1RLgn8AxeN8IKl1WRNoDfYD7VbVQVf8HzKrogpWM8WVVXa+qB4C3gZ7O9pHAh6q6UFULgPuce1CRN4HRACISB5zvbENVl6jq16parKqbgecCxBHIZU58K1V1P96E6P/6Fqjq96rqUdUVzvUqc17wJpQfVPU1J643gbXAML8yFd2bwzkZiAUedv6N5gEf4twboAg4UUSaquoeVV3qt/0Y4FhVLVLVRWoTx9U6SxCmunaqan7piohEi8hzThNMNt4mjeb+zSzlbCtdUNU8ZzG2imXbArv9tgFsqSjgSsa4zW85zy+mtv7ndt6gsyq6Ft7awggRiQRGAEtV9ScnjhSn+WSbE8dDeGsTR1ImBuCncq+vn4jMd5rQ9gE3VvK8pef+qdy2n4Akv/WK7s0RY1ZV/2Tqf95L8CbPn0TkcxE5xdn+KLAB+FRENonI+Mq9DFOTLEGY6ir/ae5PQCrQT1WbcrBJo6Jmo5rwK9BSRKL9trU7TPmjifFX/3M714yvqLCqrsb7RjiEss1L4G2qWgt0duKYWJ0Y8DaT+XsDbw2qnao2A571O++RPn3/grfpzV97YGsl4jrSeduV6z/wnVdVF6vqhXibn2birZmgqjmq+idV7QQMB+4QkcFHGYupIksQpqbE4W3T3+u0Z08K9gWdT+QZwGQRiXA+fQ47zCFHE+O7wFAROc3pUJ7Ckf9+3gBuxZuI3ikXRzaQKyJdgLGVjOFtYIyInOgkqPLxx+GtUeWLSF+8ianUTrxNYp0qOPfHQIqI/EZEwkTkcuBEvM1BR+MbvLWNu0QkXEQG4P03muH8m10hIs1UtQjvPfEAiMhQETne6Wvah7ff5nBNeiYILEGYmvIE0ATYBXwN/KeWrnsF3o7eLOBB4C28z2sE8gTVjFFVVwE34X3T/xXYg7cT9XBK+wDmqeouv+3j8L555wAvODFXJoZPnNcwD2/zy7xyRf4ATBGRHOB+nE/jzrF5ePtcvnBGBp1c7txZwFC8taws4C5gaLm4q0xVC/EmhCF47/vTwJWqutYp8jtgs9PUdiPef0/wdsJ/BuQCXwFPq+r8o4nFVJ1Yv49pSETkLWCtqga9BmNMQ2c1CFOviUgfETlOREKcYaAX4m3LNsYcJXuS2tR3bYB/4+0wzgTGquoyd0MypmGwJiZjjDEBWROTMcaYgBpME1NCQoJ26NDB7TCMMaZeWbJkyS5VbRVoX4NJEB06dCAjI8PtMIwxpl4RkfJP0PtYE5MxxpiALEEYY4wJyBKEMcaYgBpMH4QxpvYVFRWRmZlJfn7+kQsbV0VFRZGcnEx4eHilj7EEYYyptszMTOLi4ujQoQMVf9+TcZuqkpWVRWZmJh07dqz0cdbEZIyptvz8fOLj4y051HEiQnx8fJVrepYgjDFHxZJD/VCdfydLEI5iT7HbIRhjTJ1iCQK4+oOrufL9K90OwxhTRVlZWfTs2ZOePXvSpk0bkpKSfOuFhYWHPTYjI4NbbrnliNc49dRTayTWBQsWMHTo0Bo5V22xTmogOS6ZBxc9yJ2n3knaMWluh2OMqaT4+HiWL18OwOTJk4mNjWXcuHG+/cXFxYSFBX6bS09PJz09/YjX+PLLL2sk1vrIahDAuFPH0bJJSybOm+h2KMaYozRmzBhuvPFG+vXrx1133cW3337LKaecQlpaGqeeeirr1q0Dyn6inzx5Mtdccw0DBgygU6dOTJ8+3Xe+2NhYX/kBAwYwcuRIunTpwhVXXEHpbNgff/wxXbp0oXfv3txyyy1HrCns3r2biy66iO7du3PyySezYsUKAD7//HNfDSgtLY2cnBx+/fVXzjjjDHr27EnXrl1ZtGhRjd+zilgNAmgW1YwJp03gzv/eyYLNCxjQYYDbIRlTLw14ZcAh2y476TL+0OcP5BXlcf7r5x+yf0zPMYzpOYZdebsY+fbIMvsWjFlQrTgyMzP58ssvCQ0NJTs7m0WLFhEWFsZnn33GxIkTee+99w45Zu3atcyfP5+cnBxSU1MZO3bsIc8MLFu2jFWrVtG2bVv69+/PF198QXp6OjfccAMLFy6kY8eOjB49+ojxTZo0ibS0NGbOnMm8efO48sorWb58OY899hhPPfUU/fv3Jzc3l6ioKJ5//nnOPfdc7rnnHkpKSsjLy6vWPakOq0E4bupzE0lxSTy06CG3QzHGHKVLL72U0NBQAPbt28ell15K165duf3221m1alXAYy644AIiIyNJSEigdevWbN++/ZAyffv2JTk5mZCQEHr27MnmzZtZu3YtnTp18j1fUJkE8b///Y/f/e53AAwaNIisrCyys7Pp378/d9xxB9OnT2fv3r2EhYXRp08fXn75ZSZPnsz3339PXFxcdW9LlVkNwtEkvAnvXvYux7c83u1QjKm3DveJPzo8+rD7E6ITql1jKC8mJsa3fN999zFw4EDef/99Nm/ezIABAwIeExkZ6VsODQ2luPjQkY2VKXM0xo8fzwUXXMDHH39M//79mTNnDmeccQYLFy7ko48+YsyYMdxxxx1ceWXtDKqxGoSfk5NPJiE6AVXFox63wzHG1IB9+/aRlJQEwCuvvFLj509NTWXTpk1s3rwZgLfeeuuIx5x++um8/vrrgLdvIyEhgaZNm7Jx40a6devG3XffTZ8+fVi7di0//fQTiYmJXHfddVx77bUsXbq0xl9DRSxBlLNz/076vdiP1757ze1QjDE14K677mLChAmkpaXV+Cd+gCZNmvD0009z3nnn0bt3b+Li4mjWrNlhj5k8eTJLliyhe/fujB8/nn/+858APPHEE3Tt2pXu3bsTHh7OkCFDWLBgAT169CAtLY233nqLW2+9tcZfQ0UazHdSp6ena018YZCq0ueFPuzM28n6P64nMizyyAcZ00itWbOGE044we0wXJebm0tsbCyqyk033UTnzp25/fbb3Q7rEIH+vURkiaoGHO9rNYhyRISHz3qYn/f9zLMZz7odjjGmHnjhhRfo2bMnJ510Evv27eOGG25wO6QaYTWICpz16ll8t/07Nt2yibjI2hs1YEx9YjWI+sVqEDXkz4P/zK68XVaLMMY0WjbMtQJ9kvowe/Rszu50ttuhGGOMK4JagxCR80RknYhsEJHxAfbfISKrRWSFiMwVkWP99pWIyHLnZ1Yw46zI0JShRIZF2pBXY0yjFLQEISKhwFPAEOBEYLSInFiu2DIgXVW7A+8Cf/Hbd0BVezo/w4MV55Es+mkRqU+m8tPen9wKwRhjXBHMGkRfYIOqblLVQmAGcKF/AVWdr6qlE4t8DSQHMZ5q6dC8A1v2bWHy55PdDsUYU87AgQOZM2dOmW1PPPEEY8eOrfCYAQMGUDqg5fzzz2fv3r2HlJk8eTKPPfbYYa89c+ZMVq9e7Vu///77+eyzz6oQfWB1aVrwYCaIJGCL33qms60ivwc+8VuPEpEMEflaRC4KdICIXO+Uydi5c+dRBxxIu2bt+GPfP/Lqd6+yakfgOVyMMe4YPXo0M2bMKLNtxowZlZoPCbyzsDZv3rxa1y6fIKZMmcJZZ51VrXPVVXViFJOI/BZIBx7123ysM/TqN8ATInJc+eNU9XlVTVfV9FatWgUtvgmnTSA2IpZ7598btGsYY6pu5MiRfPTRR74vB9q8eTO//PILp59+OmPHjiU9PZ2TTjqJSZMmBTy+Q4cO7Nq1C4Bp06aRkpLCaaed5psSHLzPOPTp04cePXpwySWXkJeXx5dffsmsWbO488476dmzJxs3bmTMmDG8++67AMydO5e0tDS6devGNddcQ0FBge96kyZNolevXnTr1o21a9ce9vW5PS14MEcxbQXa+a0nO9vKEJGzgHuAM1W1oHS7qm51fm8SkQVAGrAxiPFWKD46njtPvZP75t/H8m3L6dmmpxthGFOnPTB7Fat/ya7Rc57YtimThp1U4f6WLVvSt29fPvnkEy688EJmzJjBZZddhogwbdo0WrZsSUlJCYMHD2bFihV079494HmWLFnCjBkzWL58OcXFxfTq1YvevXsDMGLECK677joA7r33Xl566SVuvvlmhg8fztChQxk5suwU5fn5+YwZM4a5c+eSkpLClVdeyTPPPMNtt90GQEJCAkuXLuXpp5/mscce48UXX6zw9bk9LXgwaxCLgc4i0lFEIoBRQJnRSCKSBjwHDFfVHX7bW4hIpLOcAPQHVuOi206+jQ9GfUCPxB5uhmGMKce/mcm/eentt9+mV69epKWlsWrVqjLNQeUtWrSIiy++mOjoaJo2bcrw4QfHxaxcuZLTTz+dbt268frrr1c4XXipdevW0bFjR1JSUgC46qqrWLhwoW//iBEjAOjdu7dvgr+KuD0teNBqEKpaLCJ/BOYAocA/VHWViEwBMlR1Ft4mpVjgHREB+NkZsXQC8JyIePAmsYdV1dUEERsRy/BU738aVcWJ1xjjONwn/WC68MILuf3221m6dCl5eXn07t2bH3/8kccee4zFixfTokULxowZQ35+frXOP2bMGGbOnEmPHj145ZVXWLBgwVHFWzpl+NFMF15b04IHtQ9CVT9W1RRVPU5Vpznb7neSA6p6lqomlh/Oqqpfqmo3Ve3h/H4pmHFWxZPfPsmZr5xpz0YYU0fExsYycOBArrnmGl/tITs7m5iYGJo1a8b27dv55JNPDnuOM844g5kzZ3LgwAFycnKYPXu2b19OTg7HHHMMRUVFvim6AeLi4sjJyTnkXKmpqWzevJkNGzYA8Nprr3HmmWdW67W5PS24PUldRc2jmrPo50W8s+odLu96udvhGGPwNjNdfPHFvqam0umxu3TpQrt27ejfv/9hj+/VqxeXX345PXr0oHXr1vTp08e3b+rUqfTr149WrVrRr18/X1IYNWoU1113HdOnT/d1TgNERUXx8ssvc+mll1JcXEyfPn248cYbq/W6Sr8ru3v37kRHR5eZFnz+/PmEhIRw0kknMWTIEGbMmMGjjz5KeHg4sbGxvPrqq9W6pj+brK+KSjwlpD2XxoHiA6z+w2rCQ8OPfJAxDZRN1le/2GR9QRYaEspDgx9iw+4N/GPZP9wOxxhjgsYSRDVc0PkC+rfrz5SFUygqKXI7HGOMCQrrg6gGEeHJ859EVa2JyTR6NqqvfqhOd4IliGryf1jO/kBMYxUVFUVWVhbx8fH2N1CHqSpZWVlERUVV6ThLEEfBox6u+eAakuKSmDZ4mtvhGFPrkpOTyczMJFhzoZmaExUVRXJy1eZDtQRxFEIkhGJPMX/7+m/c1Pcm2sa1dTskY2pVeHg4HTt2dDsMEyTWSX2UpgycQpGniKmfT3U7FGOMqVGWII5SpxaduKH3Dbyw9AV+yPrB7XCMMabGWIKoAfedcR9RYVFMWTjF7VCMMabGWB9EDUiMTeSNS94gvW3AhxGNMaZesgRRQ2ymV2NMQ2NNTDVoy74tDPznQBZsXuB2KMYYc9QsQdSghOgENuzewIS5E6r11KIxxtQlliBqUJPwJkweMJmvM7/mg3UfuB2OMcYcFUsQNWxMzzGkxqcyce5ESjwlbodjjDHVZgmihoWFhDFt0DTW7FrDG9+/4XY4xhhTbZYggmDECSN4YdgLjDhhhNuhGGNMtdkw1yAQEa7tda3bYRhjzFGxGkQQzf9xPqe+dCo5BYd+sbkxxtR1liCCKDYilq8yv+Lxrx53OxRjjKkySxBB1CepDyNPHMljXz3Gjv073A7HGGOqxBJEkD048EEOFB3goUUPuR2KMcZUiSWIIEtNSOXqnlfzTMYz/LzvZ7fDMcaYSrNRTLVg0oBJDOo4iOSmVfu6P2OMcZMliFqQ3DSZ0d1Gux2GMcZUiTUx1aInv32Sqz+42u0wjDGmUixB1KJ9+ft4ZfkrfLXlK7dDMcaYI7IEUYtuPflWEmMSGT93vE0Hboyp8yxB1KLYiFjuO+M+Fv60kDkb57gdjjHGHJYliFp2Xe/r6Ni8o32pkDGmzrNRTLUsIjSC54Y+R0xEjH13tTGmTrME4YKzjzvb7RCMMeaIrInJJfnF+Yz9cCwvLHnB7VCMMSagoCYIETlPRNaJyAYRGR9g/x0islpEVojIXBE51m/fVSLyg/NzVTDjdENkaCQrd67k/gX3k1eU53Y4xhhziKAlCBEJBZ4ChgAnAqNF5MRyxZYB6araHXgX+ItzbEtgEtAP6AtMEpEWwYrVDSLCnwf/mW2525j+zXS3wzHGmEMEswbRF9igqptUtRCYAVzoX0BV56tq6cfnr4HSyYrOBf6rqrtVdQ/wX+C8IMbqitPan8bQlKE88sUj7Dmwx+1wjDGmjGAmiCRgi996prOtIr8HPqnKsSJyvYhkiEjGzp07jzJcd0wbNI19+fv4yxd/cTsUY4wpo06MYhKR3wLpwJlVOU5VnweeB0hPT6+XDxV0T+zOMxc8wznHneN2KMYYU0YwE8RWoJ3ferKzrQwROQu4BzhTVQv8jh1Q7tgFQYmyDrgh/Qa3QzDGmEMEs4lpMdBZRDqKSAQwCpjlX0BE0oDngOGq6v+dnHOAc0SkhdM5fY6zrcH6cc+PDHtzGD9k/eB2KMYYAwQxQahqMfBHvG/sa4C3VXWViEwRkeFOsUeBWOAdEVkuIrOcY3cDU/EmmcXAFGdbgxUdHs38H+dz3/z73A7FGGMAkIYyH1B6erpmZGS4HcZRuW/efTy46EGWXL+EXsf0cjscY0wjICJLVDU90D57kroOGXfqOFo2acnEuRPdDsUYYyxB1CXNopox8bSJzNk4h/k/znc7HGNMI1cnhrmag/7Q5w8UlhRaE5MxxnWWIOqYJuFNmHD6BLfDMMYYa2Kqq+b9OI+Rb4+kxFPidijGmEbKEkQdtefAHt5b8x6vrXjN7VCMMY2UJYg6asQJI0hvm86kBZPIL853OxxjTCNkCaKOEhEeHvwwP+/7mWcznnU7HGNMI2QJog4b3GkwZ3U6i2mLppFdkO12OMaYRsZGMdVxj5z1CMt+XUZ0eLTboRhjGhlLEHVcr2N62TMRxhhXWBNTPfH04qeZ8vkUt8MwxjQiliDqiWW/LmPaomls3rvZ7VCMMY2EJYh6YtKASQjC5AWT3Q7FGNNIWIKoJ5KbJnNz35t59btXWbljpdvhGGMaAUsQ9cj408YTFxnHvfPudTsUY0wjYKOY6pH46Hj+PuTvtI1r63YoxphGwBJEPXNljyvdDsEY00hYE1M9lFuYy7hPx/Hpxk/dDsUY04BZgqiHIkIj+Peaf3P3Z3fjUY/b4RhjGihLEPVQRGgEUwdOZfm25by96m23wzHGNFCWIOqp0d1G0z2xO/fOu5eikiK3wzHGNECWIOqpEAnhoUEPsXHPRl5a9pLb4RhjGiBLEPXY+Z3P597T72VAhwFuh2KMaYBsmGs9JiJMHTTV7TCMMQ1UpWoQIhIjIiHOcoqIDBeR8OCGZipr055NXPn+lew+sNvtUIwxDUhlm5gWAlEikgR8CvwOeCVYQZmqyS3M5V8r/sVfvviL26EYYxqQyiYIUdU8YATwtKpeCpwUvLBMVXRP7M4V3a/g/775P7Zmb3U7HGNMA1HpBCEipwBXAB8520KDE5KpjgcGPECJp4SpC61PwhhTMyqbIG4DJgDvq+oqEekEzA9aVKbKOrXoxA29b+DFpS/yQ9YPbodjjGkAKjWKSVU/Bz4HcDqrd6nqLcEMzFTdvWfcS1RYFC2btHQ7FGNMA1DZUUxviEhTEYkBVgKrReTO4IZmqioxNpFHz3mU+Oh4t0MxxjQAlW1iOlFVs4GLgE+AjnhHMpk6aMHmBfxpzp/cDsMYU89VNkGEO889XATMUtUiQIMWlTkqS35ZwuNfP878H62byBhTfZVNEM8Bm4EYYKGIHAtkH+kgETlPRNaJyAYRGR9g/xkislREikVkZLl9JSKy3PmZVck4DXBT35tIbprMhLkTULU8boypnkolCFWdrqpJqnq+ev0EDDzcMSISCjwFDAFOBEaLyInliv0MjAHeCHCKA6ra0/kZXpk4jVdUWBQPDHiAb7Z+wwfrPnA7HGNMPVXZTupmIvK4iGQ4P3/FW5s4nL7ABlXdpKqFwAzgQv8CqrpZVVcA9q03NezKHlfSJaELE+dOpMRT4nY4xph6qLJNTP8AcoDLnJ9s4OUjHJMEbPFbz3S2VVaUk4y+FpGLqnCcAcJCwvjrOX/lxvQb7VvnjDHVUtnZXI9T1Uv81h8QkeVBiMffsaq61Xkob56IfK+qG/0LiMj1wPUA7du3D3I49c/5nc93OwRjTD1W2RrEARE5rXRFRPoDB45wzFagnd96srOtUlR1q/N7E7AASAtQ5nlVTVfV9FatWlX21I2KqvLS0pd4ZfkrbodijKlnKluDuBF4VUSaOet7gKuOcMxioLOIdMSbGEYBv6nMxUSkBZCnqgUikgD0B2yq0moQEWasmsHybcsZccIImkY2dTskY0w9UdlRTN+pag+gO9BdVdOAQUc4phj4IzAHWAO87czjNEVEhgOISB8RyQQuBZ4TkVXO4ScAGSLyHd45nx5W1dXVeH0G+PPgP7Mrbxd//fKvbodijKlHpLrj5EXkZ1WtMw3/6enpmpGR4XYYddZl71zGxz98zKZbN9E6prXb4Rhj6ggRWaKq6YH2Hc13UstRHGtq2dSBU8kvzmfawmluh2KMqSeO5jup7RHdeiQ1IZUpA6fQPbG726EYY+qJwyYIEckhcCIQoElQIjJBM/H0iW6HYIypRw7bxKSqcaraNMBPnKoeTe3DuCSnIIf759/Pyh0r3Q7FGFPHHU0fhKmHijxFTP9mOvfMu8ftUIwxdZwliEamZZOW3NX/Lmatm8WXW750OxxjTB1mCaIRurXfrSTGJDL+s/E2HbgxpkKWIBqhmIgY7j/zfhb9vIj/bPiP2+EYY+oo62hupK7tdS0Zv2SQ3DTZ7VCMMXWUJYhGKiI0gn9c+A+3wzDG1GHWxNTIbd67mT/N+ROFJYVuh2KMqWMsQTRyq3eu5vGvH+elpS+5HYoxpo6xBNHIDTl+CKe3P50pC6ewv3C/2+EYY+oQSxCNnIjw58F/ZlvuNqZ/M93tcIwxdYglCEP/9v0ZljKMR754hN0HdrsdjjGmjrAEYQCYNmgao7qOwqMet0MxxtQRNszVANAtsRvPDn3W7TCMMXWI1SBMGV9t+Yonvn7C7TCMMXWAJQhTxpsr32Tcp+NYn7Xe7VCMMS6zBGHKuOf0e4gKi+K++fe5HYoxxmWWIEwZibGJ3HHKHby96m2W/LLE7XCMMS6yBGEO8adT/kR8k3gmzrOvKDWmMbNRTOYQzaKaMW3QNPbk78GjHkLEPkcY0xhZgjAB3ZB+g9shGGNcZh8NTYU86uHN79/k042fuh2KMcYFVoMwFfKohykLpyAIK8auICzE/rsY05hYDcJUKCwkjGmDprFm1xpe++41t8MxxtQySxDmsC7ucjF92vZh0oJJ5Bfnux2OMaYWWYIwhyUiPHzWw2zJ3sIzi59xOxxjTC2yBGGOaFDHQVzX6zo6tujodijGmFpkvY6mUp4f9rzbIRhjapnVIEyl5RXl8cj/HmHH/h1uh2KMqQWWIEylZWZncs+8e5i2cJrboRhjaoElCFNpKfEpXJN2Dc9kPMOqHavcDscYE2SWIEyVTDpzEhGhEXR9piu9nuvF1uytbodkjAmSoCYIETlPRNaJyAYRGR9g/xkislREikVkZLl9V4nID87PVcGM01ReUtMkVoxdwSNnPULbuLa0iW0DwNTPp3L97OuZvW42eUV5LkdpjKkJoqrBObFIKLAeOBvIBBYDo1V1tV+ZDkBTYBwwS1Xfdba3BDKAdECBJUBvVd1T0fXS09M1IyMjKK/FHNnt/7mdl5a9RE5hDk3CmjC402B+0/U3jO422u3QjDGHISJLVDU90L5g1iD6AhtUdZOqFgIzgAv9C6jqZlVdAXjKHXsu8F9V3e0khf8C5wUxVnOU/nbe39h11y4+/e2nXNvrWlbuWMl/Nv4HAFXl8a8eZ+mvSwnWBxJjTM0L5nMQScAWv/VMoN9RHJtUvpCIXA9cD9C+ffvqRWlqTERoBGcfdzZnH3c2/3fe//mamn7c+yPjPh2HoiTFJTE0ZSjDUoYxqOMgmoQ3cTlqY0xF6nUntao+r6rpqpreqlUrt8MxfkSEmIgYADq16MS2cdt4+cKX6Zfcj3+t+BdD3xzKRz98BMCuvF1sy93mZrjGmACCWYPYCrTzW092tlX22AHljl1QI1EZV7SOac2YnmMY03MMBcUFLNi8gFPbnQrAi0tfZMLcCfRp24dhKcMYljqMHok9EBGXozamcQtmDWIx0FlEOopIBDAKmFXJY+cA54hICxFpAZzjbDMNQGRYJOcefy5xkXGAd8bYBwc+SIiEMGnBJNKeS6Pz3ztT7CkGsH4LY1wStBqEqhaLyB/xvrGHAv9Q1VUiMgXIUNVZItIHeB9oAQwTkQdU9SRV3S0iU/EmGYApqro7WLEad6UmpHLPGfdwzxn3sD13Ox/98BFb9m3xfUHRea+fR3R4NMNShnFB5wtIjE10OWJjGoegDXOtbTbMtWFSVW755BZmrptJZnYmgtA3qS+3nXwbo7qOcjs8Y+o9t4a5GnPURIS/n/93fr7tZ5bdsIwHBjyARz1k5WUBsHP/Tm7++GY+3fgpBcUFLkdrTMNiNQhTL6kqIsLcTXMZ9uYwDhQfIDYilnOOO4dhKcMYccIImkY2dTtMY+o8q0GYBqd0hNPgToPJuiuLD0d/yBXdruDrzK+5+oOrfTWM77d/z8odK62j25hqsBqEaVBUlZU7VtItsRsAl75zKe+ufpeOzTv6HtA7s8OZRIRGuBypMXXD4WoQliBMg7Y1eysf/fARs9fP5rNNn5FfnE+/pH58fe3XgPdLkKLDo12O0hj3HC5B2FeOmgYtqWkS1/e+nut7X09eUR5zN831PV9RWFJI0uNJnNTqJIanDmdYyjC6JHSxB/SMcVgfhGk0osOjGZY6jItPuBiA/OJ8bul7C3lFedz92d2c+PSJdP57Zz5c/6HLkRpTN1iCMI1W08imPDDwAZbesJQtt2/hmQueITUhlVbR3nm9Pt/8OaPeHcXrK15n9wF7TtM0PtYHYUwF3vz+TW6fczvb928nVELp374/w1KGcVOfm2wWWtNgWCe1MdXkUQ8Zv2Qwa90sZq+fzS85v7DtT9sIDQll5tqZNI9qTv92/QkPDXc7VGOqxRKEMTVkb/5emkc1B6DLk11Yl7WO5lHNOe/48xiWMowhxw+hRZMW7gZpTBXYg3LG1JDS5ACw+LrFvHfZe1zU5SLmbprLFf++gtvm3AZ4n8fYuHujO0EaU0NsmKsx1RQXGceIE0Yw4oQRlHhK+Hbrt8RGxAKwaucquj3TjdT4VIamDOW09qeRGp/K8S2Pt+YoU29YE5MxQbArbxdvfv8ms9fPZsHmBRR5igCY89s5nHPcOSzeuph3V79Ll4QudEnoQmpCKi2btHQ5atMY2YNyxtSyhOgEbu53Mzf3u5ncwlzW7FzD2l1r6X1MbwBWbF/BE988QWFJoe+YVtGt+Pa6b+nQvAPfbfuOrTlb6ZLQhWObHUtoSKhbL8U0YlaDMMYlxZ5iNu/dzLpd61i7ay1rdq3hqfOfIjIskls/uZXp304HIDI0ks7xnemS0IU3L3mTsJAwfs35lbjIOF+TljHVZaOYjKln9hzYw5pd3lpH6U/WgSy+uOYLAC55+xL+vebfJMUl+Zqp0tqk8ftev3c5clPfWIIwpoGZu2ku3279lrVZBxNIl4QufHPtNwAMfnUwe/P3epNHvLePo0diD1ITUl2O3NQ11gdhTAMzuNNgBnca7FtXVXILc33rpySfQsYvGXzx8xe88f0bAIw4YQTvXfYeAFf8+wpaR7f21T66JHShdUxrm6jQlGEJwpgGQESIi4zzrT846EHfcl5RHj9k/UCIeB97KiwpZPXO1by/630OFB/wlRt3yjgePedRCksKefyrx32J47gWx9nQ3EbKEoQxDVx0eDQ92vTwrUeERrDshmV41ENmdqaviapnm54A/LjnRybMneArHxYSxnEtjuOhwQ8x4oQRZBdks2rHKhua2wg0+gSRX1TCRU99QefEOLq0iSPF+Z3UvAkhIVbdNg1XiITQvll72jdrzznHnePbnpqQyt6797I+a/3BTvKstb5k8E3mN5zzL2/5VtGtfDWNO065gy4JXSgsKSRUQm1obgPQ6BNEdn4RSc2bsOznPcz+7hff9piIUDonxpGaGEdqm4M/CbGRLkZrTO1oFtWMPkl96JPU55B9vdv25sPRH5ZJHu+vfZ+x6WMBeH3F64z9aKxvaG6XeG8CGZ46vEwzmKn7bBSTn5z8In7Ykcu6bTkHf7bnsHv/wYeZ4mMiSCmXNFIS44iNbPS51jRyqoqIsHjrYt5Z/Y4vgWzcsxGPetgxbgetYlrx5LdPMnPtzDId5KnxqSQ3TbZOchfYKKZKiosKp1f7FvRqX3Y2zp05BazfnsPabTms35bD2u05vJ2xhbzCEl+Z5BZNDqltdEqIJSLM5kM0jUPpm3v5mkdBcQEb92wkIToB8PZp5BTm8NqK18guyAYgKiyK3Am5hEooLy19iQ27NxAfHU98k3jio+M5JvYY3zlLE5EJPqtBVJPHo2zde8CbNPySx8aduRR7vPc0LETo1CrGW+PwSx7tWkRb/4Zp9FSVbbnbWLtrLdv3b2dU11EAXPbOZcxcO9M3fxVAl4QurLlpDQAD/zmQ5duWE98knoToBOKj4+nVphdTB00F4L3V71GiJb7kUlrOvuQpMKtBBEFIiNCuZTTtWkZz9omJvu2FxR5+3LWftduyWb/d20z1XeZePlzxq69Mk/BQUhJjfc1TXdo0JaVNLK1iI+2TkWk0RIRj4o7hmLhjymx/+9K3fc91ZB3IYlfeLko8B2vrl514GV1bdfXt25a7jU17N/n2j587ng27N5Q555Djh/DxFR8DcO6/zqWopOhgDaVJPCcnn8yw1GEAZPySQbPIZsRHx9M8qrlveHBjZDWIWrK/oJj12/1qG07y2JV7sH+jZUwEKYmx3oSRGEdqm1hSEuOIi7Ix6MZU1vbc7ezM20lWXhZZB7LIysuiTWwbXwIY9e4oMrMzffuyDmRxdc+reXH4i6gq4VPDKVFvQgqREFpEteDmvjczacAkikqKuP7D62kZ1bJME1iPxB50ju+MRz0UlRQRGVZ/BrNYDaIOiIkMI619C9LK9W/syi1gvdMZXtop/k7GFvb79W8kNW/iV9vw/j6udQyRYTaM0JjyEmMTSYxNrHD/jJEzyqx71OObVVdRZo+e7audlCaQE1qdAEBOYQ6fbfqMrLysMg8ZThs0jYmnTyQzO5NjnziWmPCYMgnk1n63MjRlKLvydvH6itd9TWOl+9vGtSUqLCoId+PoWIJwWUJsJAnHR3Lq8Qm+baX9G+VrG4t+2ElRibfGFxoidEyI8fZrlPZvJMbRrmU0oda/YUylhUiI7805REIY0nlIhWVbNmnJltu3AHCg6ICvFtIqphUAMeExPDjwQe92vxpKUYm3P2XD7g2+bx3098aINxjdbTRfbfmK38/6fZnmr/joeK7tdS0p8Slsz93Ouqx1vn6Vlk1aBvUpd2tiqkeKSrz9G/5DcNdty+Hn3Xm+MlHhIaQklq1tdGkTR6s4698wxm0e9bDnwJ4yySMrL4szO5xJh+YdWPbrMqYtmnbI/jm/ncOZHc7kje/f4Ip/X1HmnE0jm5J5e2a1nzGx2VwbuP0FxfywI/eQpqqdOQW+Ms2jw8sOw02MI6VNHE2tf8OYOq30PVpE2LF/Byu2r/Alj115u9h9YDd/O/dv1f4AaAmikcrKLWD99lzWbctmnfN7/fZccguKfWXaNosixS9ppLaJ47hWsUSFW/+GMY2BdVI3UvGxkZwSG8kpx8X7tqmW69/YlsO67bl8uSGLwhIP4O3f6BAf7SSNpqS2iSW1TVPaW/+GMY2KJYhGRkRIbhFNcotoBnU5ONKjqMTDT1n7Dz4tvi2H1b9k88nKbZRWMqPCQ+jc2tuv0bppJLGRYTSNCiMuKpzYyDDiosKIjQqjaVS4dzkyjLDQxjuG3Jj6LqgJQkTOA/4PCAVeVNWHy+2PBF4FegNZwOWqullEOgBrgHVO0a9V9cZgxtrYhYeGcHzrOI5vHQfdD27PKyxmw45cv9pGDv/bsJOs3ELfE+OH0yQ81Jc44qLCiXMSiTeBhPuW48olmtL1uKgwmoSHWge7MS4IWoIQkVDgKeBsIBNYLCKzVHW1X7HfA3tU9XgRGQU8Alzu7Nuoqj2DFZ+pnOiIMLonN6d7cvMy21WVgmIP2flF5OYXk5NfTG5BMTn5RWTnF/ttKyLHWc5x9m/Pzne2FZV53qMioSFysIYS6a2hxEYdJtFE+u139sVGhRFutRljqiSYNYi+wAZV3QQgIjOACwH/BHEhMNlZfhd4UuyjYr0gIkSFhxIVHkrro5jBucSjvsTi/e1NLtn5RWWSTmnCyXaSzvbsfDbuLPYlmtLnQw4nKjzEVyvx1mT8ayzhTvNYmLMt3K/J7GDZ6AirzZjGI5gJIgnY4reeCfSrqIyqFovIPqC0R7WjiCwDsoF7VXVR+QuIyPXA9QDt27ev2ehNrQgNEZo1CadZk+oPty2tzZQmi9JEU7peJtEUeJOMNxF5E40vMfmN7qpIiFAmgRzaNBbuV7M5uB4VHkpYiBARFkJYiBAeGkJ4aAhhoaXL3t9hIWIJyNQZdbWT+legvapmiUhvYKaInKSq2f6FVPV54HnwDnN1IU5TB/jXZlrFVX8OnBKPsr/wYGLJLdc0luNrOitytnmXd+R4azOl5UtHg1VXeKgQFuKXNEIPJhTfvrAQwkMO7o9wfoeFhniXQ6RcmRAinP0Hz1NaJoTwsNJrlr1uhHNsoOQW7n8953yW3BqWYCaIrUA7v/VkZ1ugMpkiEgY0A7LU+3BGAYCqLhGRjUAKYA86mKAJDRGaRoU7Dw9Wf2ro/KISv1qMN7EUFnsoLPFQXKIUlXicH6XY46Gw2EOxRykq9lDkUYr99hf5H+OUKfZ4KCzxlisuUQ4UlVDs8VBUrBR5PGWP8TvH0Sauyiif3MonsNJkFSi5+SeeqPBQYiLDiIlwfkeGERMRRkxkqNPU562hxUR690eGhVhyCoJgJojFQGcR6Yg3EYwCflOuzCzgKuArYCQwT1VVRFoBu1W1REQ6AZ2BTRhTD5TWZura19OqKiUepdijgZNVycEk5k1c3t+BEo3/sf7JzVvmYPnyx/gnt6ISDweKyidBb6LLLy5hf0FxpfqWwJvcyyQTv+RS2ncU62z3X46JDHUSz8H12EgbOVcqaAnC6VP4IzAH7zDXf6jqKhGZAmSo6izgJeA1EdkA7MabRADOAKaISBHgAW5U1d3BitWYxkBEnGYo6s2T8gXFJeQVeGtk+wuL2V/gTRz7C4rZX+hdzi0oJs/ZV7qc65TbvT/Pd1xugbcmVxki+GosgWov3sQT6leTKZ9syianmIiwevklYTbVhjGm0Sgq8XgTTmExeU5y2V9Q4iSRAInHKbu/dLlcojpQdORh2qWiI0oTStmkc3DZSTqRFSSgMs1toTX2EKpNtWGMMXgfCG0WHUKz6JqZpLLEowFqL341HSe55BaUkOesly7nFhSzM7eAn7LynGOKK/VcUKnIsBBvDSUylJ7tWvD30Wk18pr8WYIwxphqCg0RZyhzzSQcj8c76CBQE1quf/NauVpPUovgfN+2JQhjjKkjQkLE14xUF9jcA8YYYwKyBGGMMSYgSxDGGGMCsgRhjDEmIEsQxhhjArIEYYwxJiBLEMYYYwKyBGGMMSagBjMXk4jsBH46ilMkALtqKJyaZHFVjcVVNRZX1TTEuI5V1VaBdjSYBHG0RCSjogmr3GRxVY3FVTUWV9U0trisickYY0xAliCMMcYEZAnioOfdDqACFlfVWFxVY3FVTaOKy/ogjDHGBGQ1CGOMMQFZgjDGGBNQo0oQIvIPEdkhIisr2C8iMl1ENojIChHpVUfiGiAi+0RkufNzfy3F1U5E5ovIahFZJSK3BihT6/esknHV+j0TkSgR+VZEvnPieiBAmUgRecu5X9+ISIc6EtcYEdnpd7+uDXZcftcOFZFlIvJhgH21fr8qEZOb92qziHzvXDcjwP6a/XtU1UbzA5wB9AJWVrD/fOATQICTgW/qSFwDgA9duF/HAL2c5ThgPXCi2/esknHV+j1z7kGssxwOfAOcXK7MH4BnneVRwFt1JK4xwJO1/X/MufYdwBuB/r3cuF+ViMnNe7UZSDjM/hr9e2xUNQhVXQjsPkyRC4FX1etroLmIHFMH4nKFqv6qqkud5RxgDZBUrlit37NKxlXrnHuQ66yGOz/lR4FcCPzTWX4XGCwiUgficoWIJAMXAC9WUKTW71clYqrLavTvsVEliEpIArb4rWdSB954HKc4TQSfiMhJtX1xp2qfhvfTpz9X79lh4gIX7pnTNLEc2AH8V1UrvF+qWgzsA+LrQFwAlzjNEu+KSLtgx+R4ArgL8FSw3437daSYwJ17Bd7E/qmILBGR6wPsr9G/R0sQ9cNSvPOl9AD+DsyszYuLSCzwHnCbqmbX5rUP5whxuXLPVLVEVXsCyUBfEelaG9c9kkrENRvooKrdgf9y8FN70IjIUGCHqi4J9rUqq5Ix1fq98nOaqvYChgA3icgZwbyYJYiytgL+nwaSnW2uUtXs0iYCVf0YCBeRhNq4toiE430Tfl1V/x2giCv37EhxuXnPnGvuBeYD55Xb5btfIhIGNAOy3I5LVbNUtcBZfRHoXQvh9AeGi8hmYAYwSET+Va5Mbd+vI8bk0r0qvfZW5/cO4H2gb7kiNfr3aAmirFnAlc5IgJOBfar6q9tBiUib0nZXEemL998t6G8qzjVfAtao6uMVFKv1e1aZuNy4ZyLSSkSaO8tNgLOBteWKzQKucpZHAvPU6V10M65y7dTD8fbrBJWqTlDVZFXtgLcDep6q/rZcsVq9X5WJyY175Vw3RkTiSpeBc4DyIx9r9O8xrNrR1kMi8ibe0S0JIpIJTMLbYYeqPgt8jHcUwAYgD7i6jsQ1EhgrIsXAAWBUsN9UHP2B3wHfO+3XABOB9n6xuXHPKhOXG/fsGOCfIhKKNyG9raofisgUIENVZ+FNbK+JyAa8AxNGBTmmysZ1i4gMB4qduMbUQlwB1YH7daSY3LpXicD7zueeMOANVf2PiNwIwfl7tKk2jDHGBGRNTMYYYwKyBGGMMSYgSxDGGGMCsgRhjDEmIEsQxhhjArIEYcwRiEiJ38ydy0VkfA2eu4NUMIuvMW5rVM9BGFNNB5xpKoxpVKwGYUw1OXPz/8WZn/9bETne2d5BROY5k7nNFZH2zvZEEXnfmUDwOxE51TlVqIi8IN7vavjUedoZEblFvN95sUJEZrj0Mk0jZgnCmCNrUq6J6XK/fftUtRvwJN5ZQME7OeA/ncncXgemO9unA587Ewj2AlY52zsDT6nqScBe4BJn+3ggzTnPjcF5acZUzJ6kNuYIRCRXVWMDbN8MDFLVTc7kgdtUNV5EdgHHqGqRs/1XVU0QkZ1Ast9Eb6XTlf9XVTs763cD4ar6oIj8B8jFOxPtTL/vdDCmVlgNwpijoxUsV0WB33IJB/sGLwCewlvbWOzMZmpMrbEEYczRudzv91fO8pccnFTuCmCRszwXGAu+L/BpVtFJRSQEaKeq84G78U5zfUgtxphgsk8kxhxZE79ZYwH+o6qlQ11biMgKvLWA0c62m4GXReROYCcHZ9S8FXheRH6Pt6YwFqhoKuZQ4F9OEhFguvNdDsbUGuuDMKaanD6IdFXd5XYsxgSDNTEZY4wJyGoQxhhjArIahDHGmIAsQRhjjAnIEoQxxpiALEEYY4wJyBKEMcaYgP4fFziGervuN/YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"] # on training set\n",
    "val_loss_values = history_dict[\"val_loss\"] # on validation set\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"--\", color='green', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"-\", label=\"Validation loss\") \n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYt4jUivOmcZ"
   },
   "source": [
    "**Exercise**:\n",
    "Plot the learning curve with training accuracy and validation accuracy against the epoch number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "7Q7NF_-ZOmH4",
    "outputId": "ae088cee-aa74-467f-89ba-64c656a3e8c9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here:\n",
    "#\n",
    "\n",
    "history_dict = history.history\n",
    "accuracy = history_dict[\"accuracy\"] # on training set\n",
    "val_accuracy = history_dict[\"val_accuracy\"] # on validation set\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, accuracy, \"--\", color='green', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"-\", label=\"Validation accuracy\") \n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy8noYF_1Fne"
   },
   "source": [
    "## Now evaluate the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lLzC_zHxLcL",
    "outputId": "21100066-5cab-42bf-91c2-1a35475415ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.037094272673130035\n",
      "Test accuracy: 0.9876999855041504\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T-8tqYQ2KTZ",
    "outputId": "049bdba1-ab3c-481b-c903-ac6e7585875b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[[4.24651566e-14 1.14782690e-08 4.62270361e-10 ... 1.00000000e+00\n",
      "  9.42019791e-13 3.20602123e-09]\n",
      " [1.04655706e-09 2.70498936e-06 9.99997258e-01 ... 9.70590362e-12\n",
      "  1.70162079e-11 6.88508292e-14]\n",
      " [3.42486857e-07 9.99993205e-01 2.04676610e-07 ... 8.02601789e-07\n",
      "  1.19534752e-06 1.07426565e-07]\n",
      " ...\n",
      " [5.54376510e-12 3.30554464e-08 5.95826470e-12 ... 2.20892531e-08\n",
      "  9.32788424e-08 7.09498465e-07]\n",
      " [1.20115365e-12 3.17184999e-13 1.66539637e-15 ... 4.77687246e-14\n",
      "  6.30663077e-09 7.42074718e-12]\n",
      " [2.32879653e-08 1.21629148e-11 6.58720367e-09 ... 2.01170389e-15\n",
      "  1.84459514e-09 1.03891349e-11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       1.00      0.99      0.99      1135\n",
      "           2       0.98      1.00      0.99      1032\n",
      "           3       0.98      0.99      0.99      1010\n",
      "           4       0.99      0.98      0.99       982\n",
      "           5       0.98      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.99      0.98      0.99      1028\n",
      "           8       0.99      0.98      0.98       974\n",
      "           9       0.99      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 975    0    0    1    0    1    2    0    1    0]\n",
      " [   0 1127    2    1    0    3    1    1    0    0]\n",
      " [   1    0 1027    0    1    0    0    3    0    0]\n",
      " [   0    0    3 1002    0    3    0    1    1    0]\n",
      " [   0    0    1    0  967    0    3    0    2    9]\n",
      " [   1    0    0    4    0  885    1    0    0    1]\n",
      " [   4    2    0    0    1    4  945    0    2    0]\n",
      " [   0    1   13    1    0    0    0 1010    1    2]\n",
      " [   1    1    3    6    2    0    4    1  953    3]\n",
      " [   3    0    1    4    3    5    0    4    3  986]]\n"
     ]
    }
   ],
   "source": [
    "# Classification report using scikit-learn \n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred) # y_pred is an 2-d array with 10 columns\n",
    "y_predc = y_pred.argmax(axis=1) #get the class labels by choosing the class with the highest output\n",
    "y_testc = y_test.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_testc, y_predc))\n",
    "print(confusion_matrix(y_true=y_testc, y_pred=y_predc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KoJADI7IK3z"
   },
   "source": [
    "## Training Monitoring and visualization with TensorBoard\n",
    "To do good research or develop good models, you need rich, frequent feedback about what’s going on inside your models during your experiments. That’s the point of running experiments: to get information about how well a model performs as much information as possible. \n",
    "\n",
    "TensorBoard (www.tensorflow.org/tensorboard) is a browser-based application that you can run locally. It’s the best way to monitor everything that goes on inside your model during training. With TensorBoard, you can\n",
    "- Visually monitor metrics during training\n",
    "- Visualize your model architecture\n",
    "- Visualize histograms of activations and gradients\n",
    "- Explore embeddings in 3D\n",
    "\n",
    "The easiest way to use TensorBoard with a Keras model and the fit() method is to use the keras.callbacks.TensorBoard callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dZmjfdMNpB_",
    "outputId": "ecafdacc-a486-4234-aaa7-6463b21d9dc4"
   },
   "outputs": [],
   "source": [
    "# Create a log directory (whatever path and name that suits)\n",
    "!mkdir /home/ollie/Uni/Masters/ML_module/prac6/log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "d33EjwyvIOM2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1257/1257 [==============================] - 20s 15ms/step - loss: 0.1005 - accuracy: 0.9688 - val_loss: 0.0543 - val_accuracy: 0.9847\n",
      "Epoch 2/3\n",
      "1257/1257 [==============================] - 20s 16ms/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 0.0475 - val_accuracy: 0.9859\n",
      "Epoch 3/3\n",
      "1257/1257 [==============================] - 17s 14ms/step - loss: 0.0616 - accuracy: 0.9807 - val_loss: 0.0439 - val_accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=\"log\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_data=(X_val, y_val),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7178640269186966095\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaCumy5XP-IT"
   },
   "source": [
    "Once the model starts running, it will write logs at the target location. If you are running your Python script on a local machine, you can then launch the local TensorBoard server using the following command (note that the tensorboard executable should be already available if you have installed TensorFlow via pip; if not, you can install TensorBoard manually via pip install tensorboard):\n",
    "\n",
    "tensorboard --logdir /full_path_to_your_log_dir\n",
    "\n",
    "You can then navigate to the URL that the command returns in order to access the TensorBoard interface.\n",
    "\n",
    "If you are running your script in a Colab notebook, you can run an embedded TensorBoard instance as part of your notebook, using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZHApBoQsQgfI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f6a1e81c1c7401ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f6a1e81c1c7401ca\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YesYbBmzW6w-"
   },
   "source": [
    "**Exercise**:\n",
    "\n",
    "Try out different network architecture and hyperparameter settings, and observe the effect on performance using Tensorboard.\n",
    "\n",
    "You can also try out the classic [LeNet architecture (LeuCun et al. 1998)](https://d2l.ai/chapter_convolutional-neural-networks/lenet.html#sec-lenet), given in the [deep learning textbook d2l.ai](https://d2l.ai/index.html), see below. \n",
    " - 2 convolutional layers uses 5×5 kernel and a sigmoid activation function. The first convolutional layer has 6 output channels, while the second has 16. Each 2×2 AvgPooling operation (stride 2). The convolutional block emits an output with shape given by (batch size, number of channel, height, width).\n",
    " - 3 dense layers, with 120, 84, and 10 outputs, respectively. Because we are still performing classification, the 10-dimensional output layer corresponds to the number of possible output classes.\n",
    "\n",
    "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://d2l.ai/_images/lenet-vert.svg\"><img width=\"200\" alt=\"Typical cnn\" src=\"https://d2l.ai/_images/lenet-vert.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ADgQRRjiW6w_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGaWz5I2Hb7f"
   },
   "source": [
    "## Task 2 (optional): Classification using different benchmarking datasets\n",
    "\n",
    "Develop and evaluate a model with different datasets, e.g. \n",
    "- a more difficult MNIST dataset: [the Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), to load the data from keras:\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "- Cifar10 or Cifar100 dataset\n",
    "https://keras.io/api/datasets/cifar100/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5xH-eQ4H18I"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
